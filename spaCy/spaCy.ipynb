{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# intro and import"
      ],
      "metadata": {
        "id": "pQ5ZAMOkopiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It's designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hkvyn_FAnD9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kMTH5qzcl7Xc"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical models\n"
      ],
      "metadata": {
        "id": "28o5wSTBl-7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download statistical models\n",
        "\n",
        "Predict part-of-speech tags, dependency labels, named entities and more. See here for available models."
      ],
      "metadata": {
        "id": "NSw2T7fMmev-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIhNH-6UnVlP",
        "outputId": "d3b68a13-1429-42fb-e1f7-8c8c4d238f40"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check that your installed models are up to date\n",
        "\n"
      ],
      "metadata": {
        "id": "cBHNO2vDnkU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m ppacy validate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5peCaERbnZi1",
        "outputId": "d77c7a3a-0bd2-4745-c94d-1678730747f3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: No module named ppacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading statistical models\n",
        "\n"
      ],
      "metadata": {
        "id": "CBh-dIMAn5d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "zj8znq-Dnq-N"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documents, tokens and spans\n"
      ],
      "metadata": {
        "id": "DjkPvM5En_ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing text\n",
        "\n",
        "Processing text with the nlp object returns a Doc object that holds all information about the tokens, their linguistic features and their relationships."
      ],
      "metadata": {
        "id": "WcBuspo4oCA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"this is a test\")"
      ],
      "metadata": {
        "id": "hhHcaYhyn7n8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing token attributes\n",
        "\n"
      ],
      "metadata": {
        "id": "UZPHODfBoZl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in duc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h-NKdwioWfq",
        "outputId": "5e3715af-efbe-435b-8c41-d3b46a176815"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this\n",
            "is\n",
            "a\n",
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spans\n"
      ],
      "metadata": {
        "id": "s_8YV8QdpQOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing spans\n",
        "Span indices are exclusive. So doc[2:4] is a span starting at token 2, up to – but not including! – token 4."
      ],
      "metadata": {
        "id": "GaH88dhepK2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "span = duc[2 : 4]\n",
        "span.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ybvTvgQHohYG",
        "outputId": "6d6682e1-c67c-458f-b5f1-c3f7b6f347fa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a test'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a span manually"
      ],
      "metadata": {
        "id": "B3VnykDmpf2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span\n",
        "duc = nlp(\"i live in tehran city\")\n",
        "\n",
        "# Create a Span for \"tehran city\" with label GPE (geopolitical)\n",
        "span = Span(duc, 3, 5, label=\"name of city\")\n",
        "\n",
        "print(f\"text of span -> {span.text}\")\n",
        "print(f\"label of span -> {span.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPNmiCrapa6M",
        "outputId": "2db993ac-8d42-4371-b018-b7edd45e876f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text of span -> tehran city\n",
            "label of span -> name of city\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linguistic features\n"
      ],
      "metadata": {
        "id": "OIZVlh1BrHlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attributes return label IDs. For string labels, use the attributes with an underscore. For example, token.pos_.\n",
        "\n"
      ],
      "metadata": {
        "id": "oFN-8Yy0raY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-speech tags (predicted by statistical model)\n"
      ],
      "metadata": {
        "id": "nhZHr26crjdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc =nlp(\"this is a test.\")"
      ],
      "metadata": {
        "id": "xzLtnAIOqyNg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coarse-grained part-of-speech tags\n",
        "for token in duc:\n",
        "  print(f\"{token.text} -> {token.pos_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Gh1Dr-s3mZ",
        "outputId": "d99a53d0-9fbe-45f6-86ab-6a4f3a71d877"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this -> PRON\n",
            "is -> AUX\n",
            "a -> DET\n",
            "test -> NOUN\n",
            ". -> PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Fine-grained part-of-speech tags\n",
        "for token in duc:\n",
        "  print(f\"{token.text} -> {token.tag_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D4uNo5Rsmn0",
        "outputId": "3f7d4188-af4e-4d41-ae19-162ea35e6216"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this -> DT\n",
            "is -> VBZ\n",
            "a -> DT\n",
            "test -> NN\n",
            ". -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In spaCy, both `pos_` and `tag_` are attributes of a `Token` object, which represents an individual word in a document. However, they provide different levels of detail regarding the part-of-speech (POS) tagging.\n",
        "\n",
        "1. `pos_` (Coarse-grained part-of-speech tags):\n",
        "   - The `pos_` attribute provides coarse-grained part-of-speech tags, which classify words into broad categories based on their grammatical roles within a sentence. These categories typically include tags like nouns, verbs, adjectives, adverbs, pronouns, etc. For example:\n",
        "     - `'DET'`: Determiner\n",
        "     - `'VERB'`: Verb\n",
        "     - `'NOUN'`: Noun\n",
        "     - `'PUNCT'`: Punctuation\n",
        "\n",
        "2. `tag_` (Fine-grained part-of-speech tags):\n",
        "   - The `tag_` attribute provides fine-grained part-of-speech tags, which offer more detailed information about the specific grammatical properties of each word. These tags are more granular and can differentiate between different types of nouns, verbs, adjectives, etc. They often include additional information such as verb tense, noun type, singular/plural forms, etc. For example:\n",
        "     - `'DT'`: Determiner\n",
        "     - `'VBZ'`: Verb, 3rd person singular present\n",
        "     - `'NN'`: Noun, singular or mass\n",
        "     - `'.'`: Punctuation (period)\n",
        "\n",
        "In summary, while `pos_` provides a general categorization of words into broad grammatical classes, `tag_` offers a more detailed classification that includes specific grammatical features and properties of each word."
      ],
      "metadata": {
        "id": "SEB46zvYs9_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Syntactic dependencies (predicted by statistical model)\n",
        "\n"
      ],
      "metadata": {
        "id": "vsb7GaYptZPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"This is a text.\")\n",
        "for token in duc:\n",
        "  print(f\"{token.text} -> {token.dep_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKHZ4Y89s3C-",
        "outputId": "42f59bbb-f198-4e75-96e1-09ad4c5b4fb8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this -> nsubj\n",
            "is -> ROOT\n",
            "a -> det\n",
            "test -> attr\n",
            ". -> punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In spaCy, the `dep_` attribute of a `Token` object represents the syntactic dependency label assigned to that token within the dependency parse tree of the sentence. Each token in a sentence is linked to one or more other tokens through directed dependency relations, indicating the grammatical relationships between words.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "1. **Dependency labels (`dep_`)**:\n",
        "   - The `dep_` attribute provides information about the grammatical relationships between tokens in a sentence. Each token is linked to a head token (usually a word that governs the dependent token) through a specific dependency label.\n",
        "   - Dependency labels describe the syntactic role that a token plays in the structure of the sentence, such as subject, object, modifier, etc.\n",
        "   - Examples of dependency labels include:\n",
        "     - `'nsubj'`: Nominal subject (subject of a verb)\n",
        "     - `'ROOT'`: The main/root verb of the sentence\n",
        "     - `'det'`: Determiner (e.g., articles like \"a\", \"the\")\n",
        "     - `'attr'`: Attribute (a word that is an attribute of the noun it modifies)\n",
        "     - `'punct'`: Punctuation mark\n",
        "\n",
        "**Difference between dependency labels and part-of-speech (POS) tags (`pos_` and `tag_`)**:\n",
        "- Dependency labels describe the syntactic relationships between words in a sentence, while POS tags categorize words based on their grammatical properties.\n",
        "- Dependency labels provide information about how words are connected in the sentence's syntactic structure, whereas POS tags classify individual words into broad grammatical categories (e.g., noun, verb, adjective).\n",
        "- Dependency labels are used to construct the dependency parse tree of the sentence, which illustrates the hierarchical relationships between words, while POS tags are used to annotate individual words with their grammatical roles.\n",
        "\n",
        "In summary, while POS tags classify individual words, dependency labels describe the syntactic relationships between words in a sentence. They serve different purposes but are both crucial for understanding the structure and meaning of natural language text."
      ],
      "metadata": {
        "id": "2TtMUYfcurEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"this is a text.\")\n",
        "\n",
        "for token in duc:\n",
        "  print(f\"{token.text} -> {token.dep_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8JTx2nUuqTH",
        "outputId": "c10885e8-b744-4b18-aba1-221127252f6f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this -> nsubj\n",
            "is -> ROOT\n",
            "a -> det\n",
            "text -> attr\n",
            ". -> punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entities (predicted by statistical model)\n",
        "\n"
      ],
      "metadata": {
        "id": "ue6138IwyYwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"i love Google\")\n",
        "\n",
        "for ent in duc.ents:\n",
        "  print(f\"{ent.text} -> {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXzrAzCkuORU",
        "outputId": "cc561ff8-d65a-48e1-8879-133a5323a7b8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google -> ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentences (usually needs the dependency parser)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2-Plie3zKjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"this is a sentence. this is a another one.\")\n",
        "\n",
        "for sent in duc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRYtqht-y5rF",
        "outputId": "f896f7a2-ee92-461c-f0d8-c5cf9b533935"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a sentence.\n",
            "this is a another one.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base noun phrases (needs the tagger and parser)\n",
        "\n",
        "In spaCy, a \"noun chunk\" refers to a contiguous sequence of tokens in a sentence that forms a noun phrase. Noun chunks typically consist of a noun and the words that modify it, such as determiners (like \"a\" or \"the\") and adjectives. They represent the basic building blocks of sentence structure and are often useful for tasks like information extraction, parsing, and understanding the meaning of sentences.\n",
        "\n",
        "The `noun_chunks` property of a `Doc` object in spaCy is a generator that yields spans representing these noun chunks in the document. When you iterate over this generator, you get access to each noun chunk as a `Span` object.\n",
        "\n",
        "Let's break down your code:\n",
        "\n",
        "```python\n",
        "doc = nlp(\"I have a red car\")\n",
        "[chunk.text for chunk in doc.noun_chunks]\n",
        "# Output: ['I', 'a red car']\n",
        "```\n",
        "\n",
        "- `doc.noun_chunks`: This property yields spans representing the noun chunks in the document.\n",
        "- `chunk.text`: For each noun chunk span (`chunk`), it retrieves the text of the noun chunk.\n",
        "- The list comprehension iterates over all noun chunks in the document (`doc`) and collects their text representations into a list.\n",
        "\n",
        "In the example sentence \"I have a red car\", there are two noun chunks:\n",
        "1. \"I\"\n",
        "2. \"a red car\"\n",
        "\n",
        "These noun chunks represent the subject (\"I\") and the object (\"a red car\") of the sentence, respectively.\n"
      ],
      "metadata": {
        "id": "IKsbVLnI0op8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"i love tajrish place.\")\n",
        "for chunk in duc.noun_chunks:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2jRfC9tz78b",
        "outputId": "ddc7b1bf-fc88-4985-f77e-2fac9a35fe02"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "tajrish place\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label explanations\n",
        "\n"
      ],
      "metadata": {
        "id": "AKNGbAUw1B0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain(\"RB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iaUIMvcY07fd",
        "outputId": "2f40966b-338b-4abc-b9aa-ac4f506226d5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adverb'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing\n"
      ],
      "metadata": {
        "id": "E40TkfHC2YGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "d0Q8i45v1IOJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "ESYPCDlT2bXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"this is a test.\")\n",
        "displacy.render(duc, style=\"dep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "HcM5Xi0v2Ztf",
        "outputId": "73b4d5ff-226e-4961-da2a-e4144ba7a173"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"676e526964064361b8a914c4949437ca-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">this</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">test.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-676e526964064361b8a914c4949437ca-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-676e526964064361b8a914c4949437ca-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-676e526964064361b8a914c4949437ca-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-676e526964064361b8a914c4949437ca-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-676e526964064361b8a914c4949437ca-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-676e526964064361b8a914c4949437ca-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize named entities\n",
        "\n"
      ],
      "metadata": {
        "id": "fXPxXSvh3BR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc = nlp(\"mike love tehran city.\")\n",
        "displacy.render(duc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Twkfh8nF3AaM",
        "outputId": "a0a2c3e2-6266-4eba-ccbf-8ba38e356d12"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mike\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " love \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tehran city\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word vectors and similarity\n"
      ],
      "metadata": {
        "id": "JKlkOcRa3fI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duc1 = nlp(\"i like cats.\")\n",
        "duc2 = nlp(\"i like dogs.\")\n",
        "\n",
        "duc1.similarity(duc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG_HsEw62vxH",
        "outputId": "00e2367b-05b1-4765-9dd9-2a615a154931"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-add4efc0e1e6>:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  duc1.similarity(duc2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.954132408648854"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}